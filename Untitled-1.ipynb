{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import threading\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealSenseCapture:\n",
    "    def __init__(self):\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        self.pipeline.start(config=self.config)\n",
    "        self.align_to = rs.stream.color\n",
    "        self.align = rs.align(self.align_to)\n",
    "        self.queue = Queue()\n",
    "        self.running = True\n",
    "\n",
    "        def capture_loop(self):\n",
    "            while self.running:\n",
    "                frames = self.pipeline.wait_for_frames(timeout_ms=10000)\n",
    "                if not frames:\n",
    "                    continue\n",
    "\n",
    "                aligned_frames = self.align.process(frames)\n",
    "                depth_frame = aligned_frames.get_depth_frame()\n",
    "                color_frame = aligned_frames.get_color_frame()\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "\n",
    "                depth_image = np.asanyarray(depth_frame.get_data())\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                self.queue.put((color_image, depth_image))\n",
    "\n",
    "        self.thread = threading.Thread(target=capture_loop, args=(self,))\n",
    "        self.thread.start()\n",
    "\n",
    "    def read(self):\n",
    "        return self.queue.get()\n",
    "\n",
    "    def release(self):\n",
    "        self.running = False\n",
    "        self.thread.join()\n",
    "        self.pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_object_detection():\n",
    "    cap = RealSenseCapture()\n",
    "    model = YOLO(\"model_- 22 january 2024 10_45.pt\")  # Corrected the model file path\n",
    "\n",
    "    box_annotator = sv.BoxAnnotator(\n",
    "        thickness=2,\n",
    "        text_thickness=2,\n",
    "        text_scale=1\n",
    "    )\n",
    "\n",
    "    frame_count = 0\n",
    "    object_detection_counter = 0\n",
    "    while True:\n",
    "        color_image, depth_image = cap.read()\n",
    "        frame = color_image  # Define frame here\n",
    "\n",
    "        if frame_count % 20 == 0:\n",
    "            if object_detection_counter % 2 == 0:\n",
    "                data = model(color_image)\n",
    "                detection = sv.Detections.from_ultralytics(data[0])\n",
    "\n",
    "                label = [f\"{model.model.names[ci]} {con:0.2f}\"\n",
    "                         for _, _, con, ci, _ in detection]\n",
    "\n",
    "                frame = box_annotator.annotate(scene=color_image, detections=detection, labels=label)\n",
    "\n",
    "                object_detection_counter += 1\n",
    "\n",
    "        cv2.imshow(\"Live Object Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 1532.2ms\n",
      "Speed: 4.6ms preprocess, 1532.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "live_object_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
